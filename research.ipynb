{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_datareader.data as web\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# --------scalers\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "# --------cross-validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# -------- classification\n",
    "# *** Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# *** KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# *** Decision Tree; Random Forest\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# *** Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# *** SVM classifier\n",
    "from sklearn.svm import SVC\n",
    "# --------  metrics:\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500 = pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')[0]\n",
    "sp500Symbols = sorted(list(sp500['Symbol']))\n",
    "\n",
    "sp400 = pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_400_companies')[0]\n",
    "sp400Symbols = sorted(list(sp400['Ticker symbol']))[359:]\n",
    "\n",
    "sp600 = pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_600_companies')[1]\n",
    "sp600Symbols = sorted(list(sp600['Ticker symbol']))\n",
    "\n",
    "spSymbols = sp500Symbols + sp400Symbols + sp600Symbols\n",
    "\n",
    "testSymbols = ['ABC']\n",
    "currentDate = datetime.date.today()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "הרכשת נתונים"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_financial_data(symbol):\n",
    "    driver = webdriver.Chrome(executable_path=\"../chromedriver\")\n",
    "    driver.implicitly_wait(10)\n",
    "    url = 'https://seekingalpha.com/symbol/' + symbol + '/income-statement'\n",
    "    driver.get(url)\n",
    "\n",
    "    # Getting a list of the dates\n",
    "    dates_row = driver.find_element_by_class_name('dates-row')\n",
    "    dates_list = dates_row.find_elements_by_tag_name(\"li\")\n",
    "    for i in range(len(dates_list)):\n",
    "        dates_list[i] = dates_list[i].get_attribute('innerHTML')\n",
    "    \n",
    "    elem = driver.find_element_by_id('financials-tab')\n",
    "    abs_html = elem.get_attribute('innerHTML')\n",
    "    \n",
    "    # Changing to YoY view\n",
    "    view_arrow = driver.find_elements_by_class_name('select2-selection__arrow')[1]\n",
    "    view_arrow.click()\n",
    "    yoy_button = WebDriverWait(driver, 10).until(EC.presence_of_element_located(\n",
    "        (By.XPATH, \"//li[contains(text(),'YoY Growth')]\")))\n",
    "    yoy_button.click()\n",
    "    \n",
    "    elem = driver.find_element_by_id('financials-tab')\n",
    "    yoy_html = elem.get_attribute('innerHTML')\n",
    "    \n",
    "    driver.quit()\n",
    "    return (pd.read_html(abs_html), pd.read_html(yoy_html), dates_list)\n",
    "\n",
    "def clean_income_statement(statement):\n",
    "    if (statement[-30:] == \"  Created with Highstock 6.1.4\"):\n",
    "        return statement[:len(statement) - 30]\n",
    "    else:\n",
    "        return statement\n",
    "\n",
    "def clean_data(df):\n",
    "    df.replace('-',np.nan,inplace=True)\n",
    "    df.dropna(how='all', inplace=True)\n",
    "    df.dropna(axis=1, how='all', inplace=True)\n",
    "    df['Income Statement'] = df['Income Statement'].apply(clean_income_statement)\n",
    "    df.set_index('Income Statement', inplace=True)\n",
    "    df.dropna(how='all', inplace=True)\n",
    "    return df[~df.index.duplicated(keep='last')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for symbol in sp400Symbols:\n",
    "    abs_tables, yoy_tables, dates = get_financial_data(symbol)\n",
    "\n",
    "    # Taking care of Absolute tables\n",
    "    for table in abs_tables:\n",
    "        table.columns = dates\n",
    "        \n",
    "    abs_df = pd.concat(abs_tables)\n",
    "    \n",
    "    abs_df = clean_data(abs_df)\n",
    "    \n",
    "    abs_df.to_csv(f'Stocks_Data\\sp400\\{symbol}_Absolute.csv')\n",
    "    \n",
    "    # Taking care of YoY tables\n",
    "    for table in yoy_tables:\n",
    "        table.columns = dates\n",
    "        \n",
    "    yoy_df = pd.concat(yoy_tables)\n",
    "\n",
    "    yoy_df = clean_data(yoy_df)\n",
    "    \n",
    "    yoy_df.to_csv(f'Stocks_Data\\sp400\\{symbol}_YoY.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "טיפול בנתונים"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_df():\n",
    "    yoy_agg_df = pd.DataFrame()\n",
    "    abs_agg_df = pd.DataFrame()\n",
    "    agg_errors = []\n",
    "\n",
    "    for folder in os.listdir('Stocks_Data'):\n",
    "        folder_path = os.path.join('Stocks_Data',folder)\n",
    "        for file in os.listdir(folder_path):\n",
    "            symbol, view = file.split('_')\n",
    "            file_path = os.path.join(f'Stocks_Data\\{folder}',file)\n",
    "            next_df = pd.read_csv(file_path)\n",
    "            next_df.set_index('Income Statement',inplace=True)\n",
    "            next_df = next_df.T\n",
    "            next_df['Symbol'] = [symbol for x in next_df.index]\n",
    "            if view[:3] == 'YoY':\n",
    "                try:\n",
    "                    yoy_agg_df = pd.concat([yoy_agg_df, next_df.iloc[:-1]])\n",
    "                except:\n",
    "                    agg_errors.append(file)\n",
    "                    continue\n",
    "            else:\n",
    "                try:\n",
    "                    abs_agg_df = pd.concat([abs_agg_df, next_df.iloc[:-1]])\n",
    "                except:\n",
    "                    agg_errors.append(file)\n",
    "                    continue\n",
    "    \n",
    "    abs_agg_df.index.name = 'Date'\n",
    "    yoy_agg_df.index.name = 'Date'\n",
    "    \n",
    "    return abs_agg_df, yoy_agg_df, agg_errors\n",
    "\n",
    "def check_prices(df :pd.DataFrame):\n",
    "    df[['Price Before', 'Price After','Change']] = np.nan\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    df.reset_index(inplace=True)\n",
    "    \n",
    "    prices_errors = []\n",
    "    symbol = \"\"\n",
    "    for index, row in df.iterrows():\n",
    "        try:\n",
    "            if symbol != row['Symbol']:\n",
    "                print(row['Symbol'], end=\"\\r\")\n",
    "                symbol = row['Symbol']\n",
    "                start_date = row['Date']\n",
    "                stock_data = web.DataReader(symbol, 'yahoo', start_date, currentDate)\n",
    "                stock_data_avg = stock_data.groupby(pd.Grouper(freq='MS'))['Close'].mean()\n",
    "            price_before = stock_data_avg.loc[row['Date']]\n",
    "            df.loc[index, 'Price Before'] = price_before\n",
    "            price_after = stock_data_avg.loc[row['Date'] + pd.DateOffset(months=1)]\n",
    "            df.loc[index, 'Price After'] = price_after\n",
    "            if price_after > price_before * 1.01:\n",
    "                df.loc[index, 'Change'] = 1\n",
    "            else:\n",
    "                df.loc[index, 'Change'] = 0\n",
    "        except:\n",
    "            prices_errors.append(row['Symbol'])\n",
    "            continue\n",
    "            \n",
    "    df.set_index('Date',inplace=True)\n",
    "    return df, prices_errors\n",
    "\n",
    "def cols_to_numeric(df :pd.DataFrame):\n",
    "    for col in df.columns:\n",
    "        if col == \"Symbol\":\n",
    "            continue\n",
    "        df.loc[:,col] = pd.to_numeric(df[col])\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "abs_agg_df, yoy_agg_df, agg_errors = agg_df()\n",
    "yoy_agg_df, prices_errors = check_prices(yoy_agg_df)\n",
    "yoy_agg_df = yoy_agg_df[~pd.isna(yoy_agg_df['Change'])]\n",
    "\n",
    "abs_agg_df.to_csv('Absolute_Aggregate.csv')\n",
    "yoy_agg_df.to_csv('YoY_Aggregate.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "agg_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (8,15,24,38,40,41,56,62,68,76,82,83,88,93,94,102,103,106,123,129,131,134) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "abs_agg_df = pd.read_csv('Absolute_Aggregate.csv')\n",
    "abs_agg_df.set_index('Date',inplace=True)\n",
    "\n",
    "yoy_agg_df = pd.read_csv('YoY_Aggregate.csv')\n",
    "yoy_agg_df.set_index('Date',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_agg_df_filtered = abs_agg_df.dropna(axis = 1,thresh=2250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4379: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().replace(\n"
     ]
    }
   ],
   "source": [
    "# Dealing with minus values, cutting off the bracekts and adding \"-\" sign\n",
    "abs_agg_df_filtered.replace(r'\\(\\$?(\\d*,?\\d*\\.?\\d*)\\)', r'-\\1',regex=True, inplace=True)\n",
    "# Cutting off '$', '%' and ',' signs\n",
    "abs_agg_df_filtered.replace(r'\\$|\\%|\\,', '',regex=True, inplace=True)\n",
    "# Changing \"NM\" to \"0\"\n",
    "abs_agg_df_filtered.replace(r'^NM$', '0',regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1745: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n"
     ]
    }
   ],
   "source": [
    "cols_to_numeric(abs_agg_df_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4511 entries, Dec 2016 to Dec 2020\n",
      "Data columns (total 38 columns):\n",
      " #   Column                                  Non-Null Count  Dtype  \n",
      "---  ------                                  --------------  -----  \n",
      " 0   Total Revenues                          4509 non-null   float64\n",
      " 1   Total Operating Expenses                4221 non-null   float64\n",
      " 2   Operating Income                        4226 non-null   float64\n",
      " 3   Net Interest Expenses                   3936 non-null   float64\n",
      " 4   EBT, Excl. Unusual Items                4511 non-null   float64\n",
      " 5   EBT, Incl. Unusual Items                4511 non-null   float64\n",
      " 6   Income Tax Expense                      4412 non-null   float64\n",
      " 7   Earnings From Continuing Operations     4511 non-null   float64\n",
      " 8   Net Income to Company                   4511 non-null   float64\n",
      " 9   Net Income                              4511 non-null   float64\n",
      " 10  NI to Common Incl Extra Items           4226 non-null   float64\n",
      " 11  NI to Common Excl. Extra Items          4226 non-null   float64\n",
      " 12  Revenue Per Share                       4497 non-null   float64\n",
      " 13  Basic EPS                               4499 non-null   float64\n",
      " 14  Basic EPS - Continuing Ops              4499 non-null   float64\n",
      " 15  Basic Weighted Average Shares Outst.    4499 non-null   float64\n",
      " 16  Diluted EPS                             4499 non-null   float64\n",
      " 17  Diluted EPS - Continuing Ops            4499 non-null   float64\n",
      " 18  Diluted Weighted Average Shares Outst.  4499 non-null   float64\n",
      " 19  Normalized Basic EPS                    4499 non-null   float64\n",
      " 20  Normalized Diluted EPS                  4499 non-null   float64\n",
      " 21  Dividend Per Share                      3310 non-null   float64\n",
      " 22  Payout Ratio                            3376 non-null   float64\n",
      " 23  EBITDA                                  4162 non-null   float64\n",
      " 24  EBITA                                   4171 non-null   float64\n",
      " 25  EBIT                                    4171 non-null   float64\n",
      " 26  EBITDAR                                 3397 non-null   float64\n",
      " 27  Effective Tax Rate                      4412 non-null   float64\n",
      " 28  Normalized Net Income                   4511 non-null   float64\n",
      " 29  Symbol                                  4511 non-null   object \n",
      " 30  Revenues                                3633 non-null   float64\n",
      " 31  Cost Of Revenues                        3398 non-null   float64\n",
      " 32  Gross Profit                            3419 non-null   float64\n",
      " 33  Selling General & Admin Expenses        3515 non-null   float64\n",
      " 34  Interest Expense                        3204 non-null   float64\n",
      " 35  Foreign Sales                           2908 non-null   float64\n",
      " 36  Interest And Investment Income          2351 non-null   float64\n",
      " 37  Other Non Operating Income (Expenses)   2513 non-null   float64\n",
      "dtypes: float64(37), object(1)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "abs_agg_df_filtered.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "yoy_agg_df_filtered = yoy_agg_df.dropna(axis = 1,thresh=3100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4379: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().replace(\n"
     ]
    }
   ],
   "source": [
    "yoy_agg_df_filtered.replace(r'\\$|\\%|\\,', '',regex=True, inplace=True)\n",
    "yoy_agg_df_filtered.replace(r'\\(\\$?(\\d*,?\\d*\\.?\\d*)\\)', r'-\\1',regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1745: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n"
     ]
    }
   ],
   "source": [
    "cols_to_numeric(yoy_agg_df_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3568 entries, 2017-12-01 to 2020-12-01\n",
      "Data columns (total 25 columns):\n",
      " #   Column                                  Non-Null Count  Dtype  \n",
      "---  ------                                  --------------  -----  \n",
      " 0   Total Revenues                          3565 non-null   float64\n",
      " 1   Total Operating Expenses                3335 non-null   float64\n",
      " 2   Operating Income                        3202 non-null   float64\n",
      " 3   EBT, Excl. Unusual Items                3377 non-null   float64\n",
      " 4   EBT, Incl. Unusual Items                3201 non-null   float64\n",
      " 5   Earnings From Continuing Operations     3174 non-null   float64\n",
      " 6   Net Income to Company                   3156 non-null   float64\n",
      " 7   Net Income                              3148 non-null   float64\n",
      " 8   Revenue Per Share                       3563 non-null   float64\n",
      " 9   Basic EPS                               3146 non-null   float64\n",
      " 10  Basic EPS - Continuing Ops              3159 non-null   float64\n",
      " 11  Basic Weighted Average Shares Outst.    3566 non-null   float64\n",
      " 12  Diluted EPS                             3146 non-null   float64\n",
      " 13  Diluted EPS - Continuing Ops            3159 non-null   float64\n",
      " 14  Diluted Weighted Average Shares Outst.  3566 non-null   float64\n",
      " 15  Normalized Basic EPS                    3368 non-null   float64\n",
      " 16  Normalized Diluted EPS                  3368 non-null   float64\n",
      " 17  EBITDA                                  3223 non-null   float64\n",
      " 18  EBITA                                   3177 non-null   float64\n",
      " 19  EBIT                                    3158 non-null   float64\n",
      " 20  Normalized Net Income                   3370 non-null   float64\n",
      " 21  Symbol                                  3568 non-null   object \n",
      " 22  Price Before                            3568 non-null   float64\n",
      " 23  Price After                             3568 non-null   float64\n",
      " 24  Change                                  3568 non-null   float64\n",
      "dtypes: float64(24), object(1)\n",
      "memory usage: 724.8+ KB\n"
     ]
    }
   ],
   "source": [
    "yoy_agg_df_filtered.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "yoy_agg_test = yoy_agg_df_filtered.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total Revenues</th>\n",
       "      <th>Total Operating Expenses</th>\n",
       "      <th>Operating Income</th>\n",
       "      <th>EBT, Excl. Unusual Items</th>\n",
       "      <th>EBT, Incl. Unusual Items</th>\n",
       "      <th>Earnings From Continuing Operations</th>\n",
       "      <th>Net Income to Company</th>\n",
       "      <th>Net Income</th>\n",
       "      <th>Revenue Per Share</th>\n",
       "      <th>Basic EPS</th>\n",
       "      <th>...</th>\n",
       "      <th>Normalized Basic EPS</th>\n",
       "      <th>Normalized Diluted EPS</th>\n",
       "      <th>EBITDA</th>\n",
       "      <th>EBITA</th>\n",
       "      <th>EBIT</th>\n",
       "      <th>Normalized Net Income</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Price Before</th>\n",
       "      <th>Price After</th>\n",
       "      <th>Change</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-12-01</th>\n",
       "      <td>1.28</td>\n",
       "      <td>4.23</td>\n",
       "      <td>-8.80</td>\n",
       "      <td>-6.85</td>\n",
       "      <td>-30.13</td>\n",
       "      <td>-30.31</td>\n",
       "      <td>-30.31</td>\n",
       "      <td>-30.31</td>\n",
       "      <td>-3.23</td>\n",
       "      <td>-34.28</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.67</td>\n",
       "      <td>-10.25</td>\n",
       "      <td>1.27</td>\n",
       "      <td>-8.89</td>\n",
       "      <td>-8.80</td>\n",
       "      <td>-6.23</td>\n",
       "      <td>ACC</td>\n",
       "      <td>42.088500</td>\n",
       "      <td>39.309524</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-01</th>\n",
       "      <td>10.59</td>\n",
       "      <td>12.06</td>\n",
       "      <td>4.87</td>\n",
       "      <td>-22.06</td>\n",
       "      <td>70.94</td>\n",
       "      <td>69.88</td>\n",
       "      <td>69.88</td>\n",
       "      <td>69.61</td>\n",
       "      <td>9.30</td>\n",
       "      <td>68.95</td>\n",
       "      <td>...</td>\n",
       "      <td>-25.90</td>\n",
       "      <td>-24.59</td>\n",
       "      <td>9.10</td>\n",
       "      <td>5.02</td>\n",
       "      <td>4.87</td>\n",
       "      <td>-24.17</td>\n",
       "      <td>ACC</td>\n",
       "      <td>42.463684</td>\n",
       "      <td>43.227618</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-01</th>\n",
       "      <td>7.07</td>\n",
       "      <td>4.98</td>\n",
       "      <td>15.78</td>\n",
       "      <td>18.46</td>\n",
       "      <td>-27.38</td>\n",
       "      <td>-27.17</td>\n",
       "      <td>-27.17</td>\n",
       "      <td>-27.44</td>\n",
       "      <td>6.66</td>\n",
       "      <td>-27.97</td>\n",
       "      <td>...</td>\n",
       "      <td>19.94</td>\n",
       "      <td>19.08</td>\n",
       "      <td>8.93</td>\n",
       "      <td>15.33</td>\n",
       "      <td>15.78</td>\n",
       "      <td>19.89</td>\n",
       "      <td>ACC</td>\n",
       "      <td>46.831904</td>\n",
       "      <td>46.125238</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-01</th>\n",
       "      <td>-7.68</td>\n",
       "      <td>-2.04</td>\n",
       "      <td>-29.03</td>\n",
       "      <td>-69.96</td>\n",
       "      <td>-19.34</td>\n",
       "      <td>-19.49</td>\n",
       "      <td>-19.49</td>\n",
       "      <td>-14.32</td>\n",
       "      <td>-7.90</td>\n",
       "      <td>-15.81</td>\n",
       "      <td>...</td>\n",
       "      <td>-63.01</td>\n",
       "      <td>-63.31</td>\n",
       "      <td>-13.68</td>\n",
       "      <td>-28.58</td>\n",
       "      <td>-29.03</td>\n",
       "      <td>-63.11</td>\n",
       "      <td>ACC</td>\n",
       "      <td>42.595000</td>\n",
       "      <td>41.870000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-01</th>\n",
       "      <td>0.90</td>\n",
       "      <td>5.85</td>\n",
       "      <td>-1.63</td>\n",
       "      <td>-0.93</td>\n",
       "      <td>618.55</td>\n",
       "      <td>4679.43</td>\n",
       "      <td>4679.43</td>\n",
       "      <td>3153.05</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>3183.32</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.32</td>\n",
       "      <td>-2.95</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-1.63</td>\n",
       "      <td>-1.63</td>\n",
       "      <td>-1.95</td>\n",
       "      <td>ACHC</td>\n",
       "      <td>32.072500</td>\n",
       "      <td>33.693334</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-01</th>\n",
       "      <td>-0.82</td>\n",
       "      <td>-4.22</td>\n",
       "      <td>-5.39</td>\n",
       "      <td>-5.91</td>\n",
       "      <td>-6.35</td>\n",
       "      <td>-7.35</td>\n",
       "      <td>-7.35</td>\n",
       "      <td>-7.35</td>\n",
       "      <td>0.19</td>\n",
       "      <td>-6.44</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.99</td>\n",
       "      <td>-4.77</td>\n",
       "      <td>-7.56</td>\n",
       "      <td>-7.74</td>\n",
       "      <td>-5.39</td>\n",
       "      <td>-5.91</td>\n",
       "      <td>ZBRA</td>\n",
       "      <td>377.428181</td>\n",
       "      <td>401.101055</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-01</th>\n",
       "      <td>8.57</td>\n",
       "      <td>1.18</td>\n",
       "      <td>19.40</td>\n",
       "      <td>21.80</td>\n",
       "      <td>24.19</td>\n",
       "      <td>5.25</td>\n",
       "      <td>5.25</td>\n",
       "      <td>5.24</td>\n",
       "      <td>9.86</td>\n",
       "      <td>6.24</td>\n",
       "      <td>...</td>\n",
       "      <td>23.13</td>\n",
       "      <td>23.07</td>\n",
       "      <td>15.91</td>\n",
       "      <td>18.54</td>\n",
       "      <td>19.40</td>\n",
       "      <td>21.75</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>72.019499</td>\n",
       "      <td>75.964762</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-01</th>\n",
       "      <td>9.76</td>\n",
       "      <td>12.96</td>\n",
       "      <td>8.18</td>\n",
       "      <td>8.92</td>\n",
       "      <td>10.82</td>\n",
       "      <td>65.20</td>\n",
       "      <td>65.20</td>\n",
       "      <td>65.28</td>\n",
       "      <td>11.34</td>\n",
       "      <td>67.96</td>\n",
       "      <td>...</td>\n",
       "      <td>10.48</td>\n",
       "      <td>10.72</td>\n",
       "      <td>10.63</td>\n",
       "      <td>10.82</td>\n",
       "      <td>8.18</td>\n",
       "      <td>9.10</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>86.605790</td>\n",
       "      <td>84.647619</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-01</th>\n",
       "      <td>7.47</td>\n",
       "      <td>10.68</td>\n",
       "      <td>10.89</td>\n",
       "      <td>11.75</td>\n",
       "      <td>6.57</td>\n",
       "      <td>5.34</td>\n",
       "      <td>5.34</td>\n",
       "      <td>5.04</td>\n",
       "      <td>8.56</td>\n",
       "      <td>5.99</td>\n",
       "      <td>...</td>\n",
       "      <td>12.52</td>\n",
       "      <td>12.68</td>\n",
       "      <td>14.06</td>\n",
       "      <td>13.96</td>\n",
       "      <td>10.89</td>\n",
       "      <td>11.34</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>126.498095</td>\n",
       "      <td>136.842857</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-01</th>\n",
       "      <td>6.63</td>\n",
       "      <td>3.91</td>\n",
       "      <td>9.73</td>\n",
       "      <td>8.22</td>\n",
       "      <td>10.83</td>\n",
       "      <td>9.07</td>\n",
       "      <td>9.07</td>\n",
       "      <td>9.20</td>\n",
       "      <td>7.24</td>\n",
       "      <td>9.71</td>\n",
       "      <td>...</td>\n",
       "      <td>8.90</td>\n",
       "      <td>9.07</td>\n",
       "      <td>8.62</td>\n",
       "      <td>8.44</td>\n",
       "      <td>9.73</td>\n",
       "      <td>8.38</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>160.729546</td>\n",
       "      <td>162.592631</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2731 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Total Revenues  Total Operating Expenses  Operating Income  \\\n",
       "Date                                                                     \n",
       "2017-12-01            1.28                      4.23             -8.80   \n",
       "2018-12-01           10.59                     12.06              4.87   \n",
       "2019-12-01            7.07                      4.98             15.78   \n",
       "2020-12-01           -7.68                     -2.04            -29.03   \n",
       "2017-12-01            0.90                      5.85             -1.63   \n",
       "...                    ...                       ...               ...   \n",
       "2020-12-01           -0.82                     -4.22             -5.39   \n",
       "2017-12-01            8.57                      1.18             19.40   \n",
       "2018-12-01            9.76                     12.96              8.18   \n",
       "2019-12-01            7.47                     10.68             10.89   \n",
       "2020-12-01            6.63                      3.91              9.73   \n",
       "\n",
       "            EBT, Excl. Unusual Items  EBT, Incl. Unusual Items  \\\n",
       "Date                                                             \n",
       "2017-12-01                     -6.85                    -30.13   \n",
       "2018-12-01                    -22.06                     70.94   \n",
       "2019-12-01                     18.46                    -27.38   \n",
       "2020-12-01                    -69.96                    -19.34   \n",
       "2017-12-01                     -0.93                    618.55   \n",
       "...                              ...                       ...   \n",
       "2020-12-01                     -5.91                     -6.35   \n",
       "2017-12-01                     21.80                     24.19   \n",
       "2018-12-01                      8.92                     10.82   \n",
       "2019-12-01                     11.75                      6.57   \n",
       "2020-12-01                      8.22                     10.83   \n",
       "\n",
       "            Earnings From Continuing Operations  Net Income to Company  \\\n",
       "Date                                                                     \n",
       "2017-12-01                               -30.31                 -30.31   \n",
       "2018-12-01                                69.88                  69.88   \n",
       "2019-12-01                               -27.17                 -27.17   \n",
       "2020-12-01                               -19.49                 -19.49   \n",
       "2017-12-01                              4679.43                4679.43   \n",
       "...                                         ...                    ...   \n",
       "2020-12-01                                -7.35                  -7.35   \n",
       "2017-12-01                                 5.25                   5.25   \n",
       "2018-12-01                                65.20                  65.20   \n",
       "2019-12-01                                 5.34                   5.34   \n",
       "2020-12-01                                 9.07                   9.07   \n",
       "\n",
       "            Net Income  Revenue Per Share  Basic EPS  ...  \\\n",
       "Date                                                  ...   \n",
       "2017-12-01      -30.31              -3.23     -34.28  ...   \n",
       "2018-12-01       69.61               9.30      68.95  ...   \n",
       "2019-12-01      -27.44               6.66     -27.97  ...   \n",
       "2020-12-01      -14.32              -7.90     -15.81  ...   \n",
       "2017-12-01     3153.05              -0.55    3183.32  ...   \n",
       "...                ...                ...        ...  ...   \n",
       "2020-12-01       -7.35               0.19      -6.44  ...   \n",
       "2017-12-01        5.24               9.86       6.24  ...   \n",
       "2018-12-01       65.28              11.34      67.96  ...   \n",
       "2019-12-01        5.04               8.56       5.99  ...   \n",
       "2020-12-01        9.20               7.24       9.71  ...   \n",
       "\n",
       "            Normalized Basic EPS  Normalized Diluted EPS  EBITDA  EBITA  \\\n",
       "Date                                                                      \n",
       "2017-12-01                 -9.67                  -10.25    1.27  -8.89   \n",
       "2018-12-01                -25.90                  -24.59    9.10   5.02   \n",
       "2019-12-01                 19.94                   19.08    8.93  15.33   \n",
       "2020-12-01                -63.01                  -63.31  -13.68 -28.58   \n",
       "2017-12-01                 -3.32                   -2.95    0.11  -1.63   \n",
       "...                          ...                     ...     ...    ...   \n",
       "2020-12-01                 -4.99                   -4.77   -7.56  -7.74   \n",
       "2017-12-01                 23.13                   23.07   15.91  18.54   \n",
       "2018-12-01                 10.48                   10.72   10.63  10.82   \n",
       "2019-12-01                 12.52                   12.68   14.06  13.96   \n",
       "2020-12-01                  8.90                    9.07    8.62   8.44   \n",
       "\n",
       "             EBIT  Normalized Net Income  Symbol  Price Before  Price After  \\\n",
       "Date                                                                          \n",
       "2017-12-01  -8.80                  -6.23     ACC     42.088500    39.309524   \n",
       "2018-12-01   4.87                 -24.17     ACC     42.463684    43.227618   \n",
       "2019-12-01  15.78                  19.89     ACC     46.831904    46.125238   \n",
       "2020-12-01 -29.03                 -63.11     ACC     42.595000    41.870000   \n",
       "2017-12-01  -1.63                  -1.95    ACHC     32.072500    33.693334   \n",
       "...           ...                    ...     ...           ...          ...   \n",
       "2020-12-01  -5.39                  -5.91    ZBRA    377.428181   401.101055   \n",
       "2017-12-01  19.40                  21.75     ZTS     72.019499    75.964762   \n",
       "2018-12-01   8.18                   9.10     ZTS     86.605790    84.647619   \n",
       "2019-12-01  10.89                  11.34     ZTS    126.498095   136.842857   \n",
       "2020-12-01   9.73                   8.38     ZTS    160.729546   162.592631   \n",
       "\n",
       "            Change  \n",
       "Date                \n",
       "2017-12-01     0.0  \n",
       "2018-12-01     1.0  \n",
       "2019-12-01     0.0  \n",
       "2020-12-01     0.0  \n",
       "2017-12-01     1.0  \n",
       "...            ...  \n",
       "2020-12-01     1.0  \n",
       "2017-12-01     1.0  \n",
       "2018-12-01     0.0  \n",
       "2019-12-01     1.0  \n",
       "2020-12-01     1.0  \n",
       "\n",
       "[2731 rows x 25 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yoy_agg_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(df :pd.DataFrame, label_column :str, non_relevant_cols :list):\n",
    "    TRAINING_FEATURES = df.columns[df.columns != label_column]\n",
    "    TARGET_FEATURE = label_column\n",
    "\n",
    "    X = df[TRAINING_FEATURES]\n",
    "    X.drop(non_relevant_cols, axis=1, inplace=True)\n",
    "    y = df[TARGET_FEATURE]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4163: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "X, y = load_dataset(yoy_agg_test, 'Change', ['Symbol', 'Price Before', 'Price After'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total Revenues</th>\n",
       "      <th>Total Operating Expenses</th>\n",
       "      <th>Operating Income</th>\n",
       "      <th>EBT, Excl. Unusual Items</th>\n",
       "      <th>EBT, Incl. Unusual Items</th>\n",
       "      <th>Earnings From Continuing Operations</th>\n",
       "      <th>Net Income to Company</th>\n",
       "      <th>Net Income</th>\n",
       "      <th>Revenue Per Share</th>\n",
       "      <th>Basic EPS</th>\n",
       "      <th>...</th>\n",
       "      <th>Basic Weighted Average Shares Outst.</th>\n",
       "      <th>Diluted EPS</th>\n",
       "      <th>Diluted EPS - Continuing Ops</th>\n",
       "      <th>Diluted Weighted Average Shares Outst.</th>\n",
       "      <th>Normalized Basic EPS</th>\n",
       "      <th>Normalized Diluted EPS</th>\n",
       "      <th>EBITDA</th>\n",
       "      <th>EBITA</th>\n",
       "      <th>EBIT</th>\n",
       "      <th>Normalized Net Income</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-05-01</th>\n",
       "      <td>7.47</td>\n",
       "      <td>10.35</td>\n",
       "      <td>7.36</td>\n",
       "      <td>11.01</td>\n",
       "      <td>11.01</td>\n",
       "      <td>108.43</td>\n",
       "      <td>108.43</td>\n",
       "      <td>108.43</td>\n",
       "      <td>10.50</td>\n",
       "      <td>114.33</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.72</td>\n",
       "      <td>112.82</td>\n",
       "      <td>112.82</td>\n",
       "      <td>-2.45</td>\n",
       "      <td>14.43</td>\n",
       "      <td>13.75</td>\n",
       "      <td>5.23</td>\n",
       "      <td>7.04</td>\n",
       "      <td>7.36</td>\n",
       "      <td>11.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-01</th>\n",
       "      <td>-8.42</td>\n",
       "      <td>5.43</td>\n",
       "      <td>-58.59</td>\n",
       "      <td>-59.70</td>\n",
       "      <td>-57.59</td>\n",
       "      <td>-57.38</td>\n",
       "      <td>-57.38</td>\n",
       "      <td>-57.44</td>\n",
       "      <td>-8.09</td>\n",
       "      <td>-57.31</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.36</td>\n",
       "      <td>-56.95</td>\n",
       "      <td>-56.95</td>\n",
       "      <td>-1.05</td>\n",
       "      <td>-59.70</td>\n",
       "      <td>-59.37</td>\n",
       "      <td>-32.03</td>\n",
       "      <td>-58.59</td>\n",
       "      <td>-58.59</td>\n",
       "      <td>-59.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-01</th>\n",
       "      <td>0.72</td>\n",
       "      <td>-0.67</td>\n",
       "      <td>-12.39</td>\n",
       "      <td>-15.12</td>\n",
       "      <td>-19.25</td>\n",
       "      <td>-14.66</td>\n",
       "      <td>-14.66</td>\n",
       "      <td>-14.64</td>\n",
       "      <td>2.29</td>\n",
       "      <td>-13.34</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.53</td>\n",
       "      <td>-12.61</td>\n",
       "      <td>-12.61</td>\n",
       "      <td>-2.31</td>\n",
       "      <td>-13.73</td>\n",
       "      <td>-13.16</td>\n",
       "      <td>-6.52</td>\n",
       "      <td>-11.98</td>\n",
       "      <td>-12.39</td>\n",
       "      <td>-15.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-01</th>\n",
       "      <td>-5.37</td>\n",
       "      <td>-7.46</td>\n",
       "      <td>-14.42</td>\n",
       "      <td>-15.28</td>\n",
       "      <td>-42.06</td>\n",
       "      <td>-48.66</td>\n",
       "      <td>-48.66</td>\n",
       "      <td>-51.29</td>\n",
       "      <td>-4.92</td>\n",
       "      <td>-50.98</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>-50.83</td>\n",
       "      <td>-50.83</td>\n",
       "      <td>-0.51</td>\n",
       "      <td>-16.36</td>\n",
       "      <td>-16.30</td>\n",
       "      <td>-12.54</td>\n",
       "      <td>-14.00</td>\n",
       "      <td>-14.42</td>\n",
       "      <td>-16.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-01</th>\n",
       "      <td>3.31</td>\n",
       "      <td>7.12</td>\n",
       "      <td>17.39</td>\n",
       "      <td>23.23</td>\n",
       "      <td>26.08</td>\n",
       "      <td>26.63</td>\n",
       "      <td>26.63</td>\n",
       "      <td>26.63</td>\n",
       "      <td>3.68</td>\n",
       "      <td>27.05</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.36</td>\n",
       "      <td>26.98</td>\n",
       "      <td>26.98</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>23.67</td>\n",
       "      <td>23.69</td>\n",
       "      <td>13.22</td>\n",
       "      <td>17.39</td>\n",
       "      <td>17.39</td>\n",
       "      <td>23.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-01</th>\n",
       "      <td>-0.70</td>\n",
       "      <td>9.55</td>\n",
       "      <td>-24.66</td>\n",
       "      <td>115.17</td>\n",
       "      <td>222.47</td>\n",
       "      <td>202.96</td>\n",
       "      <td>202.96</td>\n",
       "      <td>207.99</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>206.25</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>210.00</td>\n",
       "      <td>210.00</td>\n",
       "      <td>0.28</td>\n",
       "      <td>115.04</td>\n",
       "      <td>117.26</td>\n",
       "      <td>-5.25</td>\n",
       "      <td>-15.44</td>\n",
       "      <td>-24.66</td>\n",
       "      <td>116.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-01</th>\n",
       "      <td>-3.54</td>\n",
       "      <td>-7.63</td>\n",
       "      <td>1.74</td>\n",
       "      <td>1.51</td>\n",
       "      <td>3.25</td>\n",
       "      <td>33.13</td>\n",
       "      <td>33.13</td>\n",
       "      <td>39.45</td>\n",
       "      <td>-1.89</td>\n",
       "      <td>41.56</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.72</td>\n",
       "      <td>41.38</td>\n",
       "      <td>41.38</td>\n",
       "      <td>-1.72</td>\n",
       "      <td>7.97</td>\n",
       "      <td>7.97</td>\n",
       "      <td>1.99</td>\n",
       "      <td>1.61</td>\n",
       "      <td>1.74</td>\n",
       "      <td>6.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-01</th>\n",
       "      <td>9.84</td>\n",
       "      <td>9.97</td>\n",
       "      <td>43.54</td>\n",
       "      <td>28.68</td>\n",
       "      <td>20.38</td>\n",
       "      <td>-3.55</td>\n",
       "      <td>-3.55</td>\n",
       "      <td>-3.55</td>\n",
       "      <td>8.94</td>\n",
       "      <td>-3.34</td>\n",
       "      <td>...</td>\n",
       "      <td>0.78</td>\n",
       "      <td>-4.55</td>\n",
       "      <td>-4.55</td>\n",
       "      <td>1.20</td>\n",
       "      <td>28.70</td>\n",
       "      <td>25.86</td>\n",
       "      <td>36.48</td>\n",
       "      <td>43.54</td>\n",
       "      <td>43.54</td>\n",
       "      <td>28.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-01</th>\n",
       "      <td>13.52</td>\n",
       "      <td>13.29</td>\n",
       "      <td>-1.65</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3.97</td>\n",
       "      <td>3.21</td>\n",
       "      <td>3.21</td>\n",
       "      <td>3.21</td>\n",
       "      <td>14.94</td>\n",
       "      <td>4.30</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.24</td>\n",
       "      <td>4.30</td>\n",
       "      <td>4.30</td>\n",
       "      <td>-1.08</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>2.07</td>\n",
       "      <td>-1.58</td>\n",
       "      <td>-1.65</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-01</th>\n",
       "      <td>-11.41</td>\n",
       "      <td>-20.06</td>\n",
       "      <td>-6.16</td>\n",
       "      <td>-10.52</td>\n",
       "      <td>-9.61</td>\n",
       "      <td>-13.54</td>\n",
       "      <td>-13.54</td>\n",
       "      <td>-13.15</td>\n",
       "      <td>-11.85</td>\n",
       "      <td>-13.70</td>\n",
       "      <td>...</td>\n",
       "      <td>0.44</td>\n",
       "      <td>-13.53</td>\n",
       "      <td>-13.53</td>\n",
       "      <td>0.21</td>\n",
       "      <td>-10.42</td>\n",
       "      <td>-10.43</td>\n",
       "      <td>-4.03</td>\n",
       "      <td>-5.31</td>\n",
       "      <td>-6.16</td>\n",
       "      <td>-9.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2184 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Total Revenues  Total Operating Expenses  Operating Income  \\\n",
       "Date                                                                     \n",
       "2019-05-01            7.47                     10.35              7.36   \n",
       "2020-09-01           -8.42                      5.43            -58.59   \n",
       "2018-12-01            0.72                     -0.67            -12.39   \n",
       "2020-12-01           -5.37                     -7.46            -14.42   \n",
       "2017-12-01            3.31                      7.12             17.39   \n",
       "...                    ...                       ...               ...   \n",
       "2019-12-01           -0.70                      9.55            -24.66   \n",
       "2017-12-01           -3.54                     -7.63              1.74   \n",
       "2017-12-01            9.84                      9.97             43.54   \n",
       "2017-12-01           13.52                     13.29             -1.65   \n",
       "2020-12-01          -11.41                    -20.06             -6.16   \n",
       "\n",
       "            EBT, Excl. Unusual Items  EBT, Incl. Unusual Items  \\\n",
       "Date                                                             \n",
       "2019-05-01                     11.01                     11.01   \n",
       "2020-09-01                    -59.70                    -57.59   \n",
       "2018-12-01                    -15.12                    -19.25   \n",
       "2020-12-01                    -15.28                    -42.06   \n",
       "2017-12-01                     23.23                     26.08   \n",
       "...                              ...                       ...   \n",
       "2019-12-01                    115.17                    222.47   \n",
       "2017-12-01                      1.51                      3.25   \n",
       "2017-12-01                     28.68                     20.38   \n",
       "2017-12-01                      0.01                      3.97   \n",
       "2020-12-01                    -10.52                     -9.61   \n",
       "\n",
       "            Earnings From Continuing Operations  Net Income to Company  \\\n",
       "Date                                                                     \n",
       "2019-05-01                               108.43                 108.43   \n",
       "2020-09-01                               -57.38                 -57.38   \n",
       "2018-12-01                               -14.66                 -14.66   \n",
       "2020-12-01                               -48.66                 -48.66   \n",
       "2017-12-01                                26.63                  26.63   \n",
       "...                                         ...                    ...   \n",
       "2019-12-01                               202.96                 202.96   \n",
       "2017-12-01                                33.13                  33.13   \n",
       "2017-12-01                                -3.55                  -3.55   \n",
       "2017-12-01                                 3.21                   3.21   \n",
       "2020-12-01                               -13.54                 -13.54   \n",
       "\n",
       "            Net Income  Revenue Per Share  Basic EPS  ...  \\\n",
       "Date                                                  ...   \n",
       "2019-05-01      108.43              10.50     114.33  ...   \n",
       "2020-09-01      -57.44              -8.09     -57.31  ...   \n",
       "2018-12-01      -14.64               2.29     -13.34  ...   \n",
       "2020-12-01      -51.29              -4.92     -50.98  ...   \n",
       "2017-12-01       26.63               3.68      27.05  ...   \n",
       "...                ...                ...        ...  ...   \n",
       "2019-12-01      207.99              -0.62     206.25  ...   \n",
       "2017-12-01       39.45              -1.89      41.56  ...   \n",
       "2017-12-01       -3.55               8.94      -3.34  ...   \n",
       "2017-12-01        3.21              14.94       4.30  ...   \n",
       "2020-12-01      -13.15             -11.85     -13.70  ...   \n",
       "\n",
       "            Basic Weighted Average Shares Outst.  Diluted EPS  \\\n",
       "Date                                                            \n",
       "2019-05-01                                 -2.72       112.82   \n",
       "2020-09-01                                 -0.36       -56.95   \n",
       "2018-12-01                                 -1.53       -12.61   \n",
       "2020-12-01                                 -0.49       -50.83   \n",
       "2017-12-01                                 -0.36        26.98   \n",
       "...                                          ...          ...   \n",
       "2019-12-01                                 -0.09       210.00   \n",
       "2017-12-01                                 -1.72        41.38   \n",
       "2017-12-01                                  0.78        -4.55   \n",
       "2017-12-01                                 -1.24         4.30   \n",
       "2020-12-01                                  0.44       -13.53   \n",
       "\n",
       "            Diluted EPS - Continuing Ops  \\\n",
       "Date                                       \n",
       "2019-05-01                        112.82   \n",
       "2020-09-01                        -56.95   \n",
       "2018-12-01                        -12.61   \n",
       "2020-12-01                        -50.83   \n",
       "2017-12-01                         26.98   \n",
       "...                                  ...   \n",
       "2019-12-01                        210.00   \n",
       "2017-12-01                         41.38   \n",
       "2017-12-01                         -4.55   \n",
       "2017-12-01                          4.30   \n",
       "2020-12-01                        -13.53   \n",
       "\n",
       "            Diluted Weighted Average Shares Outst.  Normalized Basic EPS  \\\n",
       "Date                                                                       \n",
       "2019-05-01                                   -2.45                 14.43   \n",
       "2020-09-01                                   -1.05                -59.70   \n",
       "2018-12-01                                   -2.31                -13.73   \n",
       "2020-12-01                                   -0.51                -16.36   \n",
       "2017-12-01                                   -0.29                 23.67   \n",
       "...                                            ...                   ...   \n",
       "2019-12-01                                    0.28                115.04   \n",
       "2017-12-01                                   -1.72                  7.97   \n",
       "2017-12-01                                    1.20                 28.70   \n",
       "2017-12-01                                   -1.08                  1.00   \n",
       "2020-12-01                                    0.21                -10.42   \n",
       "\n",
       "            Normalized Diluted EPS  EBITDA  EBITA   EBIT  \\\n",
       "Date                                                       \n",
       "2019-05-01                   13.75    5.23   7.04   7.36   \n",
       "2020-09-01                  -59.37  -32.03 -58.59 -58.59   \n",
       "2018-12-01                  -13.16   -6.52 -11.98 -12.39   \n",
       "2020-12-01                  -16.30  -12.54 -14.00 -14.42   \n",
       "2017-12-01                   23.69   13.22  17.39  17.39   \n",
       "...                            ...     ...    ...    ...   \n",
       "2019-12-01                  117.26   -5.25 -15.44 -24.66   \n",
       "2017-12-01                    7.97    1.99   1.61   1.74   \n",
       "2017-12-01                   25.86   36.48  43.54  43.54   \n",
       "2017-12-01                    0.96    2.07  -1.58  -1.65   \n",
       "2020-12-01                  -10.43   -4.03  -5.31  -6.16   \n",
       "\n",
       "            Normalized Net Income  \n",
       "Date                               \n",
       "2019-05-01                  11.01  \n",
       "2020-09-01                 -59.80  \n",
       "2018-12-01                 -15.11  \n",
       "2020-12-01                 -16.84  \n",
       "2017-12-01                  23.23  \n",
       "...                           ...  \n",
       "2019-12-01                 116.35  \n",
       "2017-12-01                   6.14  \n",
       "2017-12-01                  28.68  \n",
       "2017-12-01                   0.01  \n",
       "2020-12-01                  -9.97  \n",
       "\n",
       "[2184 rows x 21 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scalers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_features(X_train, X_test, scale_type):\n",
    "    X_train_scaled = pd.DataFrame()\n",
    "    if scale_type == 'minmax':\n",
    "        scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.fit_transform(X_test)\n",
    "    elif scale_type == 'standard':\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.fit_transform(X_test)\n",
    "    return scaler, X_train_scaled, X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "minmax_scaler, X_train_minmax_scaled, X_test_minmax_scaled = scale_features(X_train, X_test, 'minmax')\n",
    "\n",
    "standard_scaler, X_train_standard_scaled, X_test_standard_scaled = scale_features(X_train, X_test, 'standard')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### without scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "LR_classification_model = LogisticRegression().fit(X_train, y_train)\n",
    "y_pred = LR_classification_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is: 0.5850091407678245\n",
      "precision is: 0.6145124716553289\n",
      "recall is: 0.8262195121951219\n",
      "f1 is: 0.7048114434330298\n",
      "[[ 49 170]\n",
      " [ 57 271]]\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy is:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"precision is:\",metrics.precision_score(y_test, y_pred))\n",
    "print(\"recall is:\",metrics.recall_score(y_test, y_pred))\n",
    "print(\"f1 is:\",metrics.f1_score(y_test, y_pred))\n",
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mimax scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_classification_minmax_model = LogisticRegression().fit(X_train_minmax_scaled, y_train)\n",
    "y_pred = LR_classification_minmax_model.predict(X_test_minmax_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is: 0.5978062157221207\n",
      "precision is: 0.5989010989010989\n",
      "recall is: 0.9969512195121951\n",
      "f1 is: 0.7482837528604119\n",
      "[[  0 219]\n",
      " [  1 327]]\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy is:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"precision is:\",metrics.precision_score(y_test, y_pred))\n",
    "print(\"recall is:\",metrics.recall_score(y_test, y_pred))\n",
    "print(\"f1 is:\",metrics.f1_score(y_test, y_pred))\n",
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### standard scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_classification_standard_model = LogisticRegression().fit(X_train_standard_scaled, y_train)\n",
    "y_pred = LR_classification_standard_model.predict(X_test_standard_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is: 0.5959780621572212\n",
      "precision is: 0.6059405940594059\n",
      "recall is: 0.9329268292682927\n",
      "f1 is: 0.7346938775510204\n",
      "[[ 20 199]\n",
      " [ 22 306]]\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy is:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"precision is:\",metrics.precision_score(y_test, y_pred))\n",
    "print(\"recall is:\",metrics.recall_score(y_test, y_pred))\n",
    "print(\"f1 is:\",metrics.f1_score(y_test, y_pred))\n",
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_k_for_KNN(X_train, y_train):\n",
    "    parameters = {'n_neighbors':range(3,16,2)}\n",
    "    knn = KNeighborsClassifier()\n",
    "    clf = GridSearchCV(knn, parameters,scoring=make_scorer(metrics.precision_score))\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    best_K = clf.best_params_['n_neighbors']\n",
    "    \n",
    "    return clf, best_K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### without scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_classification_model, best_K = find_best_k_for_KNN(X_train, y_train)\n",
    "y_pred = KNN_classification_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best K is: 13\n",
      "accuracy is: 0.5612431444241316\n",
      "precision is: 0.6105527638190955\n",
      "recall is: 0.7408536585365854\n",
      "f1 is: 0.6694214876033057\n",
      "[[ 64 155]\n",
      " [ 85 243]]\n"
     ]
    }
   ],
   "source": [
    "print(\"best K is:\",best_K)\n",
    "print(\"accuracy is:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"precision is:\",metrics.precision_score(y_test, y_pred))\n",
    "print(\"recall is:\",metrics.recall_score(y_test, y_pred))\n",
    "print(\"f1 is:\",metrics.f1_score(y_test, y_pred))\n",
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mimax scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_classification_minmax_model, best_K = find_best_k_for_KNN(X_train_minmax_scaled, y_train)\n",
    "y_pred = KNN_classification_minmax_model.predict(X_test_minmax_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best K is: 13\n",
      "accuracy is: 0.6014625228519196\n",
      "precision is: 0.6011029411764706\n",
      "recall is: 0.9969512195121951\n",
      "f1 is: 0.7499999999999999\n",
      "[[  2 217]\n",
      " [  1 327]]\n"
     ]
    }
   ],
   "source": [
    "print(\"best K is:\",best_K)\n",
    "print(\"accuracy is:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"precision is:\",metrics.precision_score(y_test, y_pred))\n",
    "print(\"recall is:\",metrics.recall_score(y_test, y_pred))\n",
    "print(\"f1 is:\",metrics.f1_score(y_test, y_pred))\n",
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### standard scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_classification_standard_model, best_K = find_best_k_for_KNN(X_train_standard_scaled, y_train)\n",
    "y_pred = KNN_classification_standard_model.predict(X_test_standard_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best K is: 5\n",
      "accuracy is: 0.5118829981718465\n",
      "precision is: 0.5905044510385756\n",
      "recall is: 0.6067073170731707\n",
      "f1 is: 0.5984962406015037\n",
      "[[ 81 138]\n",
      " [129 199]]\n"
     ]
    }
   ],
   "source": [
    "print(\"best K is:\",best_K)\n",
    "print(\"accuracy is:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"precision is:\",metrics.precision_score(y_test, y_pred))\n",
    "print(\"recall is:\",metrics.recall_score(y_test, y_pred))\n",
    "print(\"f1 is:\",metrics.f1_score(y_test, y_pred))\n",
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_decision_tree_params(X_train, y_train):\n",
    "    parameters = {'max_depth':range(2,11), 'min_samples_split':range(5,21)}\n",
    "    dt = DecisionTreeClassifier()\n",
    "    clf = GridSearchCV(dt, parameters,scoring=make_scorer(metrics.precision_score))\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    best_max_depth = clf.best_params_['max_depth']\n",
    "    best_min_samples_split = clf.best_params_['min_samples_split']\n",
    "    \n",
    "    return clf, best_max_depth, best_min_samples_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### without scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_classification_model, best_max_depth, best_min_samples_split = find_best_decision_tree_params(X_train, y_train)\n",
    "y_pred = DT_classification_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best max depth is: 10\n",
      "best min samples split is: 20\n",
      "accuracy is: 0.5685557586837294\n",
      "precision is: 0.6474358974358975\n",
      "recall is: 0.6158536585365854\n",
      "f1 is: 0.63125\n",
      "[[109 110]\n",
      " [126 202]]\n"
     ]
    }
   ],
   "source": [
    "print(\"best max depth is:\",best_max_depth)\n",
    "print(\"best min samples split is:\",best_min_samples_split)\n",
    "print(\"accuracy is:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"precision is:\",metrics.precision_score(y_test, y_pred))\n",
    "print(\"recall is:\",metrics.recall_score(y_test, y_pred))\n",
    "print(\"f1 is:\",metrics.f1_score(y_test, y_pred))\n",
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mimax scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_classification_minmax_model, best_max_depth, best_min_samples_split = find_best_decision_tree_params(X_train_minmax_scaled, y_train)\n",
    "y_pred = DT_classification_minmax_model.predict(X_test_minmax_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best max depth is: 10\n",
      "best min samples split is: 19\n",
      "accuracy is: 0.4040219378427788\n",
      "precision is: 1.0\n",
      "recall is: 0.006097560975609756\n",
      "f1 is: 0.012121212121212121\n",
      "[[219   0]\n",
      " [326   2]]\n"
     ]
    }
   ],
   "source": [
    "print(\"best max depth is:\",best_max_depth)\n",
    "print(\"best min samples split is:\",best_min_samples_split)\n",
    "print(\"accuracy is:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"precision is:\",metrics.precision_score(y_test, y_pred))\n",
    "print(\"recall is:\",metrics.recall_score(y_test, y_pred))\n",
    "print(\"f1 is:\",metrics.f1_score(y_test, y_pred))\n",
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### standard scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_classification_standard_model, best_max_depth, best_min_samples_split = find_best_decision_tree_params(X_train_standard_scaled, y_train)\n",
    "y_pred = DT_classification_standard_model.predict(X_test_standard_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best max depth is: 10\n",
      "best min samples split is: 18\n",
      "accuracy is: 0.4954296160877514\n",
      "precision is: 0.6007751937984496\n",
      "recall is: 0.4725609756097561\n",
      "f1 is: 0.5290102389078498\n",
      "[[116 103]\n",
      " [173 155]]\n"
     ]
    }
   ],
   "source": [
    "print(\"best max depth is:\",best_max_depth)\n",
    "print(\"best min samples split is:\",best_min_samples_split)\n",
    "print(\"accuracy is:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"precision is:\",metrics.precision_score(y_test, y_pred))\n",
    "print(\"recall is:\",metrics.recall_score(y_test, y_pred))\n",
    "print(\"f1 is:\",metrics.f1_score(y_test, y_pred))\n",
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_random_forest_params(X_train, y_train):\n",
    "    parameters = {'n_estimators':range(50,551,100)}\n",
    "    rf = RandomForestClassifier()\n",
    "    clf = GridSearchCV(rf, parameters,scoring=make_scorer(metrics.precision_score))\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    best_n_estimators = clf.best_params_['n_estimators']\n",
    "    \n",
    "    return clf, best_n_estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### without scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_classification_model, best_n_estimators = find_best_random_forest_params(X_train, y_train)\n",
    "y_pred = RF_classification_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best number of estimators is: 10\n",
      "accuracy is: 0.5850091407678245\n",
      "precision is: 0.6222760290556901\n",
      "recall is: 0.7835365853658537\n",
      "f1 is: 0.6936572199730094\n",
      "[[ 63 156]\n",
      " [ 71 257]]\n"
     ]
    }
   ],
   "source": [
    "print(\"best number of estimators is:\",best_max_depth)\n",
    "print(\"accuracy is:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"precision is:\",metrics.precision_score(y_test, y_pred))\n",
    "print(\"recall is:\",metrics.recall_score(y_test, y_pred))\n",
    "print(\"f1 is:\",metrics.f1_score(y_test, y_pred))\n",
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mimax scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_classification_minmax_model, best_n_estimators = find_best_random_forest_params(X_train_minmax_scaled, y_train)\n",
    "y_pred = RF_classification_minmax_model.predict(X_test_minmax_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best number of estimators is: 10\n",
      "accuracy is: 0.5996343692870201\n",
      "precision is: 0.600739371534196\n",
      "recall is: 0.9908536585365854\n",
      "f1 is: 0.7479861910241657\n",
      "[[  3 216]\n",
      " [  3 325]]\n"
     ]
    }
   ],
   "source": [
    "print(\"best number of estimators is:\",best_max_depth)\n",
    "print(\"accuracy is:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"precision is:\",metrics.precision_score(y_test, y_pred))\n",
    "print(\"recall is:\",metrics.recall_score(y_test, y_pred))\n",
    "print(\"f1 is:\",metrics.f1_score(y_test, y_pred))\n",
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### standard scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_classification_standard_model, best_n_estimators = find_best_random_forest_params(X_train_standard_scaled, y_train)\n",
    "y_pred = RF_classification_standard_model.predict(X_test_standard_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best number of estimators is: 10\n",
      "accuracy is: 0.5484460694698354\n",
      "precision is: 0.622356495468278\n",
      "recall is: 0.6280487804878049\n",
      "f1 is: 0.6251896813353566\n",
      "[[ 94 125]\n",
      " [122 206]]\n"
     ]
    }
   ],
   "source": [
    "print(\"best number of estimators is:\",best_max_depth)\n",
    "print(\"accuracy is:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"precision is:\",metrics.precision_score(y_test, y_pred))\n",
    "print(\"recall is:\",metrics.recall_score(y_test, y_pred))\n",
    "print(\"f1 is:\",metrics.f1_score(y_test, y_pred))\n",
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naïve Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### without scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_classification_model = GaussianNB().fit(X_train, y_train)\n",
    "y_pred = NB_classification_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is: 0.6014625228519196\n",
      "precision is: 0.6011029411764706\n",
      "recall is: 0.9969512195121951\n",
      "f1 is: 0.7499999999999999\n",
      "[[  2 217]\n",
      " [  1 327]]\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy is:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"precision is:\",metrics.precision_score(y_test, y_pred))\n",
    "print(\"recall is:\",metrics.recall_score(y_test, y_pred))\n",
    "print(\"f1 is:\",metrics.f1_score(y_test, y_pred))\n",
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mimax scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_classification_minmax_model = GaussianNB().fit(X_train_minmax_scaled, y_train)\n",
    "y_pred = NB_classification_minmax_model.predict(X_test_minmax_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is: 0.396709323583181\n",
      "precision is: 0.0\n",
      "recall is: 0.0\n",
      "f1 is: 0.0\n",
      "[[217   2]\n",
      " [328   0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy is:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"precision is:\",metrics.precision_score(y_test, y_pred))\n",
    "print(\"recall is:\",metrics.recall_score(y_test, y_pred))\n",
    "print(\"f1 is:\",metrics.f1_score(y_test, y_pred))\n",
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### standard scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_classification_standard_model = GaussianNB().fit(X_train_standard_scaled, y_train)\n",
    "y_pred = NB_classification_standard_model.predict(X_test_standard_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is: 0.44972577696526506\n",
      "precision is: 0.5849056603773585\n",
      "recall is: 0.28353658536585363\n",
      "f1 is: 0.38193018480492813\n",
      "[[153  66]\n",
      " [235  93]]\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy is:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"precision is:\",metrics.precision_score(y_test, y_pred))\n",
    "print(\"recall is:\",metrics.recall_score(y_test, y_pred))\n",
    "print(\"f1 is:\",metrics.f1_score(y_test, y_pred))\n",
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg = xgb.XGBClassifier(verbosity = 0, booster = 'gbtree', objective = 'binary:logistic', min_child_weight = 2,\n",
    "                           max_delta_step = 2 ,learning_rate = 0.9, n_estimators = 8, tree_method = 'hist',\n",
    "                           max_depth = 7)\n",
    "# dart\n",
    "# gbtree\n",
    "# gblinear\n",
    "\n",
    "xg_reg.fit(X_train,y_train)\n",
    "\n",
    "y_pred = xg_reg.predict(X_test)\n",
    "\n",
    "print(\"accuracy is:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"precision is:\",metrics.precision_score(y_test, y_pred))\n",
    "print(\"recall is:\",metrics.recall_score(y_test, y_pred))\n",
    "print(\"f1 is:\",metrics.f1_score(y_test, y_pred))\n",
    "metrics.confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"accuracy is:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"precision is:\",metrics.precision_score(y_test, y_pred))\n",
    "print(\"recall is:\",metrics.recall_score(y_test, y_pred))\n",
    "print(\"f1 is:\",metrics.f1_score(y_test, y_pred))\n",
    "metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# xg_reg = xgb.XGBClassifier(verbosity = 0, booster = 'gbtree', objective = 'binary:logistic', min_child_weight = 1,\n",
    "#                            max_delta_step = 0.4 ,learning_rate = 0.9, n_estimators = 9, tree_method = 'hist',\n",
    "#                            max_depth = 6)\n",
    "# accuracy is: 0.585\n",
    "# precision is: 0.6745098039215687\n",
    "# recall is: 0.6745098039215687\n",
    "# f1 is: 0.6745098039215687\n",
    "# array([[ 62,  83],\n",
    "#        [ 83, 172]], dtype=int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"accuracy is:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"precision is:\",metrics.precision_score(y_test, y_pred))\n",
    "print(\"recall is:\",metrics.recall_score(y_test, y_pred))\n",
    "print(\"f1 is:\",metrics.f1_score(y_test, y_pred))\n",
    "metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# xg_reg = xgb.XGBClassifier(objective ='reg:pseudohubererror',min_child_weight = 1.1, max_delta_step = 1,\n",
    "#                            n_estimators = 9)\n",
    "# accuracy is: 0.6225\n",
    "# precision is: 0.6573426573426573\n",
    "# recall is: 0.7800829875518672\n",
    "# f1 is: 0.713472485768501\n",
    "# array([[ 61,  98],\n",
    "#        [ 53, 188]], dtype=int64)\n",
    "\n",
    "# xg_reg = xgb.XGBClassifier(objective ='reg:logistic',min_child_weight = 1.9, max_delta_step = 0.4, learning_rate = 0.9,\n",
    "#                 n_estimators = 15, tree_method = 'hist', max_depth = 10)\n",
    "# accuracy is: 0.625\n",
    "# precision is: 0.6666666666666666\n",
    "# recall is: 0.7551867219917012\n",
    "# f1 is: 0.708171206225681\n",
    "# array([[ 68,  91],\n",
    "#        [ 59, 182]], dtype=int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X_train_standard_scaled).fillna(float('inf'),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
